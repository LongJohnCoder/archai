# use this as overriding config for quick compile testing

common:
  detect_anomaly: True # if True, PyTorch code will run 6X slower

dataset: &dataset
  max_batches: 2 # if >= 0 then only these many batches are generated (useful for debugging)

nas:
  search:
    data_parallel: False
    resume: False # ignore checkpoint file if it exist
    model_desc:
      n_cells: 3 # number of cells
      n_nodes: 3 # number of nodes in a cell
      out_nodes: 1 # last n nodes to concate output from
    loader:
      batch: 32
      dataset: *dataset
    trainer:
      epochs: 2
      logger_freq: 1 # after every N updates dump loss and other metrics in logger
  eval:
    data_parallel: False
    checkpoint:
      freq: 1
    model_desc:
      n_cells: 3 # number of cells
      n_nodes: 3 # number of nodes in a cell
      out_nodes: 1 # last n nodes to concate output from
    loader:
      batch: 32
      dataset: *dataset
    trainer:
      epochs: 20
      logger_freq: 1 # after every N updates dump loss and other metrics in logger
      validation:
        logger_freq: 1
