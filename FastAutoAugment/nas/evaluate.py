from typing import Optional

import torch

from ..common.trainer import Trainer
from ..common.config import Config
from ..common.common import get_logger
from .model_desc import ModelDesc, RunMode
from .micro_builder import MicroBuilder
from . import nas_utils

def eval_arch(conf_eval:Config, micro_builder:Optional[MicroBuilder]):
    logger = get_logger()

    # region conf vars
    conf_loader       = conf_eval['loader']
    save_filename    = conf_eval['save_filename']
    conf_model_desc   = conf_eval['model_desc']
    conf_checkpoint = conf_eval['checkpoint']
    resume = conf_eval['resume']
    conf_train = conf_eval['trainer']
    final_desc_filename = conf_eval['final_desc_filename']
    full_desc_filename = conf_eval['full_desc_filename']
    # endregion

    # load model desc file to get template model
    template_model_desc = ModelDesc.load(final_desc_filename)

    device = torch.device(conf_eval['device'])

    model, checkpoint = nas_utils.model_and_checkpoint(
                                conf_checkpoint, resume, full_desc_filename,
                                conf_model_desc, device,
                                run_mode=RunMode.EvalTrain,
                                micro_builder=micro_builder,
                                template_model_desc=template_model_desc)

    # get data
    train_dl, _, test_dl = nas_utils.get_data(conf_loader)
    assert train_dl is not None and test_dl is not None

    trainer = Trainer(conf_train, model, device, checkpoint)
    trainer.fit(train_dl, test_dl)

    # save metrics
    train_metrics, test_metrics = trainer.get_metrics()
    train_metrics.report_best()
    train_metrics.save('eval_train_metrics')
    if test_metrics:
        test_metrics.report_best()
        test_metrics.save('eval_test_metrics')

    # save model
    save_path = model.save(save_filename)
    if save_path:
        logger.info(f"Model saved in {save_path}")
    else:
        logger.info("Model is not saved because file path config not set")







